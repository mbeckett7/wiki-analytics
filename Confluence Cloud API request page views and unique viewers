# Imports
from java.net import URL
from javax.net.ssl import HttpsURLConnection
from java.util import Base64
from java.io import BufferedReader, InputStreamReader
import json
from java.lang import Thread  # Importing Thread for sleep method
import random

# Define the base URLs for views and viewers
base_urls = {
    "views": "https://harvardwiki.atlassian.net/wiki/rest/api/analytics/content/{}/views",
    "viewers": "https://harvardwiki.atlassian.net/wiki/rest/api/analytics/content/{}/viewers"
}

# Extract contentId from the base column
content_id = value  # 'value' refers to the current cell value of the base column in OpenRefine

# Define an optional 'fromDate' value if needed (e.g., "2023-01-01"). Set to None or empty string if not needed.
from_date = ""  # Modify this value as needed.

# Your username and API token
username = "user@domain.edu"
api_token = "<API-KEY>"

# Create authentication string and encode it
auth_string = "{}:{}".format(username, api_token)
encoded_auth = Base64.getEncoder().encodeToString(auth_string.encode("UTF-8"))

# Define retry parameters
max_retries = 4
last_retry_delay_millis = 5000
max_retry_delay_millis = 30000
jitter_multiplier_range = [0.7, 1.3]

# Function to build URL with optional query parameter
def build_url(base_url, content_id, from_date):
    if from_date:
        return base_url.format(content_id) + "?fromDate=" + from_date
    else:
        return base_url.format(content_id)

# Function to open a connection and fetch result for a given type
def fetch_result(url):
    retry_count = 0
    last_retry_delay_millis_local = last_retry_delay_millis
    while retry_count < max_retries:
        # Open a connection to the URL
        connection = URL(url).openConnection()
        connection.setRequestMethod("GET")
        connection.setRequestProperty("Authorization", "Basic " + encoded_auth)
        connection.setRequestProperty("Accept", "application/json")

        # Get the response code
        response_code = connection.getResponseCode()
        retry_delay_millis = -1

        if response_code == 200:
            # Read the response
            bufferedReader = BufferedReader(InputStreamReader(connection.getInputStream(), "UTF-8"))
            response_data = []
            line = bufferedReader.readLine()
            while line is not None:
                response_data.append(line)
                line = bufferedReader.readLine()
            bufferedReader.close()

            # Convert response data to a single string
            response_str = ''.join(response_data)

            # Parse JSON response
            json_response = json.loads(response_str)

            # Extract the count value
            count_value = json_response.get('count', None)

            # Return as string without conversion
            return str(count_value)

        elif response_code == 429:
            if connection.getHeaderField("Retry-After"):
                retry_delay_millis = 1000 * int(connection.getHeaderField("Retry-After"))
            else:
                retry_delay_millis = min(2 * last_retry_delay_millis_local, max_retry_delay_millis)

        if retry_delay_millis > 0:
            jitter = random.uniform(jitter_multiplier_range[0], jitter_multiplier_range[1])
            retry_delay_millis = int(retry_delay_millis * jitter)
            Thread.sleep(retry_delay_millis)
            retry_count += 1
        else:
            break

    return "Error: HTTP response code " + str(response_code)

# Build URLs for both requests including an optional 'fromDate' parameter
views_url = build_url(base_urls["views"], content_id, from_date)
viewers_url = build_url(base_urls["viewers"], content_id, from_date)

# Fetch results from both URLs and join with a pipe separator
views_result = fetch_result(views_url)
viewers_result = fetch_result(viewers_url)
result = views_result + " | " + viewers_result

# Return the result
return result